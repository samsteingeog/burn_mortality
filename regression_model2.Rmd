---
title: "regression_model2"
author: "Samantha Hing"
date: "4/21/2020"
output: html_document
---

```{r, include=FALSE}
#knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(caTools)
library(caret)
library(MASS)
library(glmnet)
library(randomForest)
library(e1071)
library(rminer)

```

### Run these files first
```{r render needed files}
# Run these files to get data frames

rmarkdown::render('./ClimateStations_RAWS.Rmd') # gives us weather dataframe ("fires_weather")
rmarkdown::render('./FireDBR_calcs.Rmd') # gives us dbr dataframe ("dbr_data")

```

## Join data sources

These models are trained on two data sets: 
 * "all" data set: 100 randomly selected sample points in each of the ~100 fires (~10k observations total)
 * "ave" data set: values taken across each of the ~100 fires (~100 observations total)
 
In the "all" data set, weather and fire characteristic varaibles are constant across all 100 sample points, leading to issues with model fit. The "ave" data set was created to avoid this issue. 

```{r read in other data}
# read in average data csv file
# gives us elevation, slope, aspect averages for whole fire
average_data <- read_csv("data/avg_std.csv")

#import file with data from 10k sample points
sample_pts <- read_csv("data/sample_pts")

#clean up date values
sample_pts$ALARM_DATE <- ymd_hms(sample_pts$ALARM_DATE) #change from char to date
sample_pts$CONT_DATE <- ymd_hms(sample_pts$CONT_DATE)
sample_pts$fireduration <- interval(sample_pts$ALARM_DATE, sample_pts$CONT_DATE) %>% #coerce duration dates into time values
  as.duration()

#adding in biomass and vegetation variables 
sumDB <- read_csv("data/SumDB.txt") %>% #Dead Biomass (sum across fire - kg/ha)
  dplyr::select(-OBJECTID) %>%
  rename("OBJECTID" = "FIREID")

sumLB <- read_csv("data/SumLB.txt") %>% #live biomass (sum across fire - kg/ha)
  dplyr::select(-OBJECTID) %>%
  rename("OBJECTID" = "FIREID")

meanTD <- read_csv("data/MeanTD.txt") %>% #tree density (mean- #trees/ha)
  dplyr::select(-OBJECTID) %>%
  rename("OBJECTID" = "FIREID")

VegCover <- read_csv("data/VegTypeSum.txt") %>% #land cover (sum across fire - m^2 of each type)
  dplyr::select(-OBJECTID) %>%
  rename("OBJECTID" = "FIREID", "conifer" = "VALUE_1", "shrub" = "VALUE_2", "herbaceous" = "VALUE_3", "barren_other" = "VALUE_4", 
         "urban" = "VALUE_5", "hardwood" = "VALUE_6", "water" = "VALUE_7", "agricultural" = "VALUE_8")

```

```{r create df of "all" data}

all_data <- full_join(sample_pts, fires_weather, by = "OBJECTID") %>%
  dplyr::select(-ALARM_DATE.y, -CONT_DATE.y, -Shape_Leng.y, -YEAR_, -STATE) #drop extraneous variables

# drop geometry values to avoid bugs later
 all_dat <- all_data %>%
   dplyr::select(-geometry)

#Export
# write.csv(all_df, file = "all_data.csv")

#drop missing values
all_dat <- all_dat %>%  
  filter(!(dem == -9999)) %>%
  filter(!(dbr == 0)) %>%
  filter(!(is.na(GIS_ACRES))) %>%
  filter(!(is.na(wind_max))) %>%
  mutate(fireduration = replace(fireduration, fireduration== as.duration(0), as.duration(43200))) #add in 12 hours of fireduration for fires that started and ended the same day
 
#change datetime data to numeric for later regression functions
all_dat$fireduration <- as.numeric(all_dat$fireduration) 
all_dat$DeadBio <- as.numeric(all_dat$DeadBio)


all_dat <- data.frame(all_dat) 

```

```{r create df of "ave" data}
# join all the datasets (averages, weather, dbr, biomass, landcover type)
ave_data <- full_join(average_data, fires_weather, by = "OBJECTID") %>%
  full_join(dbr_data, by = "OBJECTID") %>%
  dplyr::select(-YEAR_, -STATE) %>% #drop extraneous variables
  left_join(sumDB, by = "OBJECTID") %>%
  dplyr::select(-COUNT, -AREA) %>%
  rename("DeadBio_SUM" = "SUM") %>%
  left_join(sumLB, by = "OBJECTID") %>%
  dplyr::select(-COUNT, -AREA) %>%
  rename("LiveBio_SUM" = "SUM") %>%
  left_join(meanTD, by = "OBJECTID") %>%
  dplyr::select(-COUNT, -AREA) %>%
  rename("TreeDens" = "MEAN") %>%
  left_join(VegCover, by = "OBJECTID")

# drop geometry values to avoid bugs later
 ave_df <- ave_data %>%
   dplyr::select(-geometry) 

#Export
# write.csv(all_df, file = "all_data.csv")

#drop missing values for DEM and derived data
#drop values without info on dbr
ave_df <- ave_df %>%  
  filter(!is.na(DEM_MEAN)) %>%
  filter(!is.na(dbr_means)) %>%
  filter(!is.na(wind_speed)) %>%
  filter(!is.na(wind_max))

# add fire duration to dataframe
ave_df <- ave_df %>%
  mutate(fireduration = as.duration(interval(ALARM_DATE, CONT_DATE))) %>%
# add in 12 hours of fireduration for fires that started and ended the same day
  mutate(fireduration = replace(fireduration, fireduration== as.duration(0), as.duration(43200))) %>%
  mutate(fireduration = as.numeric(fireduration)) %>% # change to numeric
  data.frame()


```


## Data splitting

Randomly assign data to train and test pools using 75-25 split. 

```{r data splitting all}

# Test/Train split(s)
 set.seed(1)

 data_split = sample.split(all_df, SplitRatio = 0.75) #setting up testing and training split
 train <- subset(all_df, data_split == TRUE)
 test <-subset(all_df, data_split == FALSE)

#seperating into ind and dep variables for later 
 
all_dbr <- all_dat$dbr #just dependent variables
test_dbr <- test$dbr
train_dbr <- train$dbr

all_ind <- all_dat %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, wind_max, month_humid, week_humid) 
test_ind <- test %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES,
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)
train_ind <- train %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES,
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)
 
all_df <- cbind(all_dbr, all_ind) %>% #had to create a data table with no NAs for later functions
  rename("dbr" = "all_dbr")

all_df <- na.omit(all_df)

#re do data frames now that observations with missing data in relevant fields has been removed

all_ind <- all_dat %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, wind_max, month_humid, week_humid) 

all_dbr <- all_dat$dbr #just dependent variables

#Uncomment and run following lines to export
# all_export <- cbind(all_dat$OBJECTID, all_ind, all_dbr)
# write.csv(all_export, file = "data/all_export.csv")

```


```{r data splitting ave}

# Test/Train split(s)
 set.seed(1234)

 data_split = sample.split(ave_df, SplitRatio = 0.75) #setting up testing and training split
 train
 ave_train<- subset(ave_df, data_split == TRUE)
 ave_test <-subset(ave_df, data_split == FALSE)

#seperating into ind and dep variables for later 
 
ave_df_og <- ave_df

ave_dbr <- ave_df$dbr_means #just dependent variables
ave_te_dbr <- ave_test$dbr_means
ave_tr_dbr <- ave_train$dbr_means

ave_ind <- ave_df %>% #just independent variables (using mean biomass)
  dplyr::select(slope_MEAN, aspect_MEAN, DEM_MEAN, LiveBio_MEAN, DeadBio_MEAN, TreeDens, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, wind_max,  month_humid, week_humid, 
          conifer, shrub, herbaceous, barren_other, urban, hardwood, water, agricultural)

ave_ind_alt <- ave_df %>% #Just independent variables (using summed biomass)
  dplyr::select(slope_MEAN, aspect_MEAN, DEM_MEAN, LiveBio_SUM, DeadBio_SUM, TreeDens, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, wind_max, month_humid, week_humid, 
          conifer, shrub, herbaceous, barren_other, urban, hardwood, water, agricultural)

ave_te_ind <- ave_test %>% #just independent variables (test)
  dplyr::select(slope_MEAN, aspect_MEAN, DEM_MEAN, LiveBio_MEAN, DeadBio_MEAN, TreeDens, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, wind_max,  month_humid, week_humid, 
          conifer, shrub, herbaceous, barren_other, urban, hardwood, water, agricultural)

ave_tr_ind <- ave_train %>% #just independent variables (train)
  dplyr::select(slope_MEAN, aspect_MEAN, DEM_MEAN, LiveBio_MEAN, DeadBio_MEAN, TreeDens, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, wind_max,  month_humid, week_humid, 
          conifer, shrub, herbaceous, barren_other, urban, hardwood, water, agricultural)

#Uncomment and run following lines to export
# ave_export_sum <- cbind(ave_df$OBJECTID, ave_ind_alt, ave_dbr)
# write.csv(ave_export_sum, file = "data/ave_export_sum.csv")
 
```

## OLS model

```{r OLS all}

#create the model the model using all data
all_ols <- lm(dbr ~ slope + aspect + dem + LivingBio + DeadBio + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + wind_max + month_humid + week_humid, 
          data = all_df)

#check residuals 
sum(abs(all_ols$residuals)) 
#1334108 on 5/2/2020

#Check fit 
all_df$pred_dbr <- predict(all_ols, newdata = all_df)

ggplot(all_df) +
  geom_point(aes(x = dbr, y = pred_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("OLS All Data") +
  xlab("dBR") + 
  ylab("Predicted dBR")

#Poor predictive performance

```

```{r OLS ave}

#create the model using ave data

ave_ols1 <- lm(dbr_means ~ slope_MEAN + aspect_MEAN + DEM_MEAN + LiveBio_MEAN + DeadBio_MEAN + TreeDens + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + wind_max + month_humid + week_humid +
          conifer + shrub + herbaceous + barren_other + urban + hardwood + water + agricultural, 
          data = ave_df_og) #This uses mean biomass

ave_ols2 <- lm(dbr_means ~ slope_MEAN + aspect_MEAN + DEM_MEAN + LiveBio_SUM + DeadBio_SUM + TreeDens + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + wind_max + month_humid + week_humid +
          conifer + shrub + herbaceous + barren_other + urban + hardwood + water + agricultural,
          data = ave_df_og) #This uses summed biomass

#Check fit 
ave_df$pred_dbr1 <- predict(ave_ols1, newdata = ave_df) #mean biomass
ave_df$pred_dbr2 <- predict(ave_ols2, newdata = ave_df) #sum biomass

ggplot(ave_df) +
  geom_point(aes(x = dbr_means, y = pred_dbr1), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("OLS Average Data (Biomass_Mean)") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

#png(filename = "graphics/olsAve.png")

ggplot(ave_df) +
  geom_point(aes(x = dbr_means, y = pred_dbr2), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("OLS Average Data (Biomass_Sum)") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

#dev.off()

#sum of the residuals for each
sum(abs(ave_ols1$residuals)) #8546 on 5/2/2020
sum(abs(ave_ols2$residuals)) #8750 on 5/2/2020

```

### Use stepwise approach to OLS

```{r OLS stepwise all}
#trying a stepwise function to select only most relevant variables based on AIC
 #Input is the linear model (w/ all parameters) derived above 
 #k - degrees of freedom for penalty (2 for true AIC); direction - both (try adding and substracting terms)

 all_AIC <- stepAIC(all_ols, direction = "both", k = 2)

# Check with variables were retained in the model
 summary(all_AIC) # Dropped fire duration and month precip; week precip also have poor significance values
 
 all_df$aic_dbr <- predict(all_AIC, newdata = all_df) #predict using pared down model
 
 ggplot(all_df) + #doesn't seem to make much difference
   geom_point(aes(x = dbr, y = aic_dbr), alpha = 0.4) +
   geom_abline(slope = 1) +
   xlim(0,1000) +
   ylim(0,1000) +
   theme_minimal() +
   ggtitle("OLS Stepwise All Data") +
   xlab("dBR") + 
   ylab("Predicted dBR")

# overall still has poor predictive capabilities and model is fit is poor
 
```

```{r OLS stepwise ave}
#trying a stepwise function to select only most relevant variables based on AIC

#Input is the linear model (w/ all parameters) derived above 
#k - degrees of freedom for penalty (2 for true AIC); direction - both (try adding and substracting terms)
ave_AIC1 <- stepAIC(ave_ols1, direction = "both", k = 2) #biomass mean
ave_AIC2 <- stepAIC(ave_ols2, direction = "both", k = 2) #biomass sum

#check with variables were retained in the model
 summary(ave_AIC1)
 summary(ave_AIC2)
 
#Check sum of residuals
sum(abs(ave_AIC1$residuals)) # 8825 on 5/2/2020
sum(abs(ave_AIC2$residuals)) # 8834 on 5/2/2020

ave_df$aic_dbr1 <- predict(ave_AIC1, newdata = ave_df) #predict using pared down model
ave_df$aic_dbr2 <- predict(ave_AIC2, newdata = ave_df) #predict using pared down model

ggplot(ave_df) + #doesn't seem to make much difference
  geom_point(aes(x = dbr_means, y = aic_dbr1), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("OLS Stepwise Ave Data (mean biomass)") +
  xlab("Mean dBR") + 
  ylab("Predicted mean dBR")

ggplot(ave_df) + #doesn't seem to make much difference
  geom_point(aes(x = dbr_means, y = aic_dbr2), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("OLS Stepwise Ave Data (sum biomass)") +
  xlab("Mean dBR") + 
  ylab("Predicted mean dBR")

```

 ## Random Forest 
 
```{r RF all}

#setting up random forest
set.seed(1) #set seed for reproducability

all_forest = randomForest(x = all_ind, y = all_dbr, ntree = 300, mtry = 5) #documentation recs using 1/3 # of ind variables for mtry
#tried with various ntree and mtry values and got nearly identical results

import_all <- all_forest$importance #extract importance of each variable to final fit
#elevation/slope/aspect/living bio most important; precip values were least

#Extract predicted values
all_df$rf_dbr <- all_forest$predicted

#Check MSE and residuals
sum(all_forest$mse) #sum MSE 9610976 (on 5/2/2020)
mean(all_forest$mse) #mean MSE 32036
mean(abs(all_df$dbr-all_df$rf_dbr)) #128 (on 5/2/2020)

# png(file = "graphics/rfAll.png")

ggplot(all_df) + 
  geom_point(aes(x = dbr, y = rf_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("Random Forest - All Sample Points") +
  xlab("dBR") + 
  ylab("Predicted dBR")

# dev.off()

#Best fit model for "all" data set. Re-fit model using test-train split in code chunk below, and model seemed similar

```

```{r RF ave}
#setting up Random Forest
set.seed(1) #set seed for reproducability 

ave_forest1 <- randomForest(x = ave_ind, y = ave_dbr, ntree = 300, mtry = 8) #documentation recs using 1/3 # of ind variables for mtry; 
ave_forest2 <- randomForest(x = ave_ind_alt, y = ave_dbr, ntree = 300, mtry = 8)

#Use "importance" ranking (RF doesn't allow for traditional coefficients)
import_ave1 <- ave_forest$importance
import_ave2 <- ave_forest_alt$importance
#fireduration/elevation/fire size/aspect most important; precip values and non-conifer/shrub/hardwood land cover classes were least [roughly similar for both forests]

#extract predicted values
ave_df$rf_dbr1 <- ave_forest1$predicted 
ave_df$rf_dbr2 <- ave_forest2$predicted

#check residuals
sum(abs(ave_df$rf_dbr1-ave_df$dbr_means)) #9948 on 5/2/2020
sum(abs(ave_df$rf_dbr2-ave_df$dbr_means)) #10320 on 5/2/2020

#Residuals are higher than ols and model fit appears worse (see plots below)

ggplot(ave_df) + 
  geom_point(aes(x = dbr_means, y = rf_dbr1), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("Random Forest Ave Data (mean biomass)") +
  xlab("Mean dBR") + 
  ylab("Predicted mean dBR")

ggplot(ave_df) +
  geom_point(aes(x = dbr_means, y = rf_dbr2), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("Random Forest Ave Data (sum biomass)") +
  xlab("Mean dBR") + 
  ylab("Predicted mean dBR")


```

## Support Vector Machine

```{r SVM all}
#set up Support Vector Machine

all_svm <- train(all_ind, all_dbr, method = "svmLinear2", trControl = control) #using same cv settings as before w/ stepwise

#Predict values
all_df$svm_dbr <- predict(all_svm, newx = all_df)

#Inspect fit
ggplot(all_df) + 
  geom_point(aes(x = dbr, y = svm_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("SVM All Data") +
  xlab("dBR") + 
  ylab("Predicted dBR")

#Not close; RF selected as best model for all values data set

```

```{r SVM ave}
#Set up Support Vector Machines
set.seed(1) #set seed for reproducibility 

## Method 1 - caret packaged
ave_svm1 <- train(ave_ind, ave_dbr, method = "svmLinear", trControl = control) #using same cv settings as before w/ stepwise
ave_svm2 <- train(ave_ind_alt, ave_dbr, method = "svmLinear2", trControl = control) 

#predict new data
ave_df$svm_dbr1 <- predict(ave_svm1, newx = ave_df)
ave_df$svm_dbr2 <- predict(ave_svm2, newx = ave_df)

#check residuals
sum(abs(ave_df$svm_dbr1-ave_df$dbr_means)) #8038 (5/2/2020) mean - 78, median - 38
sum(abs(ave_df$svm_dbr2-ave_df$dbr_means)) #8350 (5/2/2020)
#Improvement over OLS/Stepwise OLS/RF

#Check importance of variables
importance_SVM1 <- varImp(ave_svm1, data=ave_ind)
importance_SVM1 <- importance_SVM1$importance

importance_SVM2 <- varImp(ave_svm2, data=ave_ind)
importance_SVM2 <- importance_SVM2$importance

## Method 2: e1071 package

ave_svm_1 <- svm(x = ave_ind, y = ave_dbr)
ave_svm_2 <- svm(x = ave_ind_alt, y = ave_dbr)

#predict values on alternate SVM
ave_df$svm_dbr_1 <- predict(ave_svm_1, newx = ave_df)
ave_df$svm_dbr_2 <- predict(ave_svm_2, newx = ave_df)

#Check residuals for alternate SVM
sum(abs(ave_svm_1$residuals)) #6175 on 5/2/2020
sum(abs(ave_svm_alt_1$residuals)) #6302 on 5/2/2020

#residuals improved but model seems overfit
#checking with a test-train split in code chunk below confirmed this

## Method 3: rminer package

M <- fit(ave_dbr~., data=ave_ind, model="svm", kpar=list(sigma=0.10), C=2)
#svm.imp <- Importance(M, data=ave_ind)

M_alt <- fit(ave_dbr~., data=ave_ind_alt, model="svm", kpar=list(sigma=0.10), C=2)
#svm_imp_alt <- Importance(M_alt, data=ave_ind_alt)

#predict new values
ave_df$svm_m_dbr <- predict(M, newdata = ave_ind)
ave_df$svm_m_dbr_alt <- predict(M_alt, newdata = ave_ind_alt)

#check residuals
sum(abs(ave_df$svm_m_dbr-ave_df$dbr_means)) #3308 w/ wind max, 2814 w/ veg
sum(abs(ave_df$svm_m_dbr_alt-ave_df$dbr_means)) #3284 w/ wind max, 3001 w/ veg

#best residuals and fit, but model seems severly overfit (confirmed with test-train split below)

## Selected Method 1 as our best fit average value model

#png(file = "graphics/SVMAveFinal.png")

ggplot(ave_df) + 
  geom_point(aes(x = dbr_means, y = svm_dbr1), alpha = 0.5, size = 3) +
  geom_abline(slope = 1) +
  xlim(0,750) +
  ylim(0,750) +
  theme_minimal() +
  ggtitle("SVM Average Data (mean Biomass)") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

# dev.off()


```
## Check model fit on test/train split

```{r test-train split all}

#setting up random forest
set.seed(1) #set seed for reproducability

#New forest with training data
test_forest = randomForest(x = train_ind, y = train_dbr, ntree = 300, mtry = 5) #documentation recs using 1/3 # of ind variables for mtry
#tried with various ntree and mtry values and got nearly identical results

#predict new values on test set
test_forest_pred <- predict(test_forest, newdata = test_ind)

check_all <- cbind(data.frame(test_dbr), data.frame(test_forest_pred))

#check residuals
sum(abs(check_all$test_dbr-check_all$test_forest_pred)) #298269 (5/2/2020)
mean(abs(check_all$test_dbr-check_all$test_forest_pred)) #128

import_test <- test_forest$importance #extract importance of each variable to final fit
#generally same importance ranking as full model

#Inspect the plot of test fit

ggplot(check_all) + 
  geom_point(aes(x = test_dbr, y = test_forest_pred), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal() +
  ggtitle("Random Forest - All Sample Points") +
  xlab("dBR") + 
  ylab("Predicted dBR")

# Looks about the same as the fit of full-data frame model

```

```{r test-train split ave}
# Check svm models using t-t split data from before
set.seed(123) #set seed for reproducibility 

#Test the different methods from before 
ave_svm_tt1 <- train(ave_tr_ind, ave_tr_dbr, method = "svmLinear2", trControl = control) 
ave_svm_tt2 <- svm(x = ave_tr_ind, y = ave_tr_dbr) 
ave_svm_tt3 <- fit(ave_tr_dbr~., data=ave_tr_ind, model="svm", kpar=list(sigma=0.10), C=2)

#predict new data
test_pred1 <- predict(ave_svm_tt1, newdata = ave_te_ind)
test_pred2 <- predict(ave_svm_tt2, newdata = ave_te_ind)
test_pred3 <- predict(ave_svm_tt3, newdata = ave_te_ind)

check_ave_1 <- cbind(data.frame(ave_te_dbr), data.frame(test_pred1))
check_ave_2 <- cbind(data.frame(ave_te_dbr), data.frame(test_pred2))
check_ave_3 <- cbind(data.frame(ave_te_dbr), data.frame(test_pred3))

#check residuals
sum(abs(check_ave_1$ave_te_dbr-check_ave_1$test_pred1)) #2317 (5/2/2020)  mean- 89, median - 62
sum(abs(check_ave_2$ave_te_dbr-check_ave_2$test_pred2)) #2244 (5/2/2020)
sum(abs(check_ave_2$ave_te_dbr-check_ave_3$test_pred3)) #2165 (5/2/2020)
#residuals are fairly close

#Look at plots of test data fits

ggplot(check_ave_1) +  
  geom_point(aes(x = ave_te_dbr, y = test_pred1), alpha = 0.5, size = 3) +
  geom_abline(slope = 1) +
  xlim(0,750) +
  ylim(0,750) +
  theme_minimal() +
  ggtitle("SVM Test Split") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

ggplot(check_ave_2) +  
  geom_point(aes(x = ave_te_dbr, y = test_pred2), alpha = 0.5, size = 3) +
  geom_abline(slope = 1) +
  xlim(0,750) +
  ylim(0,750) +
  theme_minimal() +
  ggtitle("SVM Test Split") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

ggplot(check_ave_3) +  
  geom_point(aes(x = ave_te_dbr, y = test_pred3), alpha = 0.5, size = 3) +
  geom_abline(slope = 1) +
  xlim(0,750) +
  ylim(0,750) +
  theme_minimal() +
  ggtitle("SVM Test Split") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

#Fit for the second & third method is way off; we chose to use the first method in our report and shiny app

```

```{r compare to ols}

#compare results of svm in test-train split to ols using same data

test_ols1 <- lm(ave_tr_dbr ~ slope_MEAN + aspect_MEAN + DEM_MEAN + LiveBio_MEAN + DeadBio_MEAN + TreeDens + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + wind_max + month_humid + week_humid +
          conifer + shrub + herbaceous + barren_other + urban + hardwood + water + agricultural, 
          data = ave_tr_ind) #This uses mean biomass

#Predict in test set 
te_dbr_ols1 <- predict(test_ols1, newdata = ave_te_ind) #mean biomass

check_ols_1 <- cbind(data.frame(ave_te_dbr), data.frame(te_dbr_ols1))

#Check fit
sum(abs(check_ols_1$ave_te_dbr-check_ols_1$te_dbr_ols1)) #2848 (5/2/2020)  mean- 109, median - 71

ggplot(check_ols_1) +  
  geom_point(aes(x = ave_te_dbr, y = te_dbr_ols1), alpha = 0.5, size = 3) +
  geom_abline(slope = 1) +
  xlim(0,750) +
  ylim(0,750) +
  theme_minimal() +
  ggtitle("OLS Test Split") +
  xlab("Mean dBR") + 
  ylab("Predicted Mean dBR")

#similar, but SVM seems to perform slightly better based on residuals and visual inspection of fit

```