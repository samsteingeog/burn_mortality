---
title: "Regression"
author: "Sam Stein"
date: "4/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(caTools)
library(caret)
library(MASS)
library(glmnet)

```

### Run these files first
1. ClimateStations_RAWS.Rmd
2. FireDBR_calcs.Rmd

## Join data sources


```{r read data}
#import Yiyi's file with data from 10k sample points
sample_pts <- read_csv("data/sample_pts")

#clean up date values
sample_pts$ALARM_DATE <- ymd_hms(sample_pts$ALARM_DATE) #change from char to date
sample_pts$CONT_DATE <- ymd_hms(sample_pts$CONT_DATE)
#sample_pts$duration <- as.numeric(sample_pts$duration) #couldn't figure out how to extract just first digits of string (maybe a regex?)
sample_pts$fireduration <- interval(sample_pts$ALARM_DATE, sample_pts$CONT_DATE) %>% #coerce duration dates into time values
  as.duration()
```

```{r make final tables}

all_data <- full_join(sample_pts, fires_weather, by = "OBJECTID") %>%
  dplyr::select(-ALARM_DATE.y, -CONT_DATE.y, -Shape_Leng.y, -YEAR_, -STATE) #drop extraneous variables

# make exportable version
 all_df <- all_data %>%
   dplyr::select(-geometry)

# write.csv(all_df, file = "all_data.csv")

#drop missing values for DEM and derived data
#drop values without info on dbr
all_df <- all_df %>%  
  filter(!(dem == -9999)) %>%
  filter(!(dbr == 0)) 

#add in 12 hours of fireduration for fires that started and ended the same day
all_df <- all_df %>%
  mutate(fireduration = replace(fireduration, fireduration== as.duration(0), as.duration(43200)))
 
#change datetime data to numeric for later regression functions
all_df$fireduration <- as.numeric(all_df$fireduration)

#create averaged values for each fire
summ_df <- all_df %>%
  group_by(OBJECTID) %>%
  summarise(mean(dbr), mean(slope), mean(aspect), mean(dem), 
            mean(LivingBio), mean(DeadBio), 
            mean(GIS_ACRES), mean(fireduration), 
            mean(wind_speed), mean(month_precip), mean(week_precip), mean(month_humid), mean(week_humid), mean(week_temp), mean(month_temp))

summ_df <- summ_df %>%
  rename("dbr" = "mean(dbr)", "slope" = "mean(slope)", "aspect" = "mean(aspect)", "dem" = "mean(dem)", "LivingBio" = "mean(LivingBio)", "DeadBio" = "mean(DeadBio)", "GIS_ACRES" = "mean(GIS_ACRES)", "fireduration" = "mean(fireduration)", "wind_speed" = "mean(wind_speed)", "month_precip" = "mean(month_precip)", "week_precip" = "mean(week_precip)", "month_humid" = "mean(month_humid)", "week_humid" = "mean(week_humid)", "week_temp" = "mean(week_temp)", "month_temp" = "mean(month_temp)")

#confirm that data seems correct 
#summary(all_df) 
```


```{r data splitting}

# Test/Train split(s)
 set.seed(1)
 
 data_split = sample.split(all_df, SplitRatio = 0.75) #setting up testing and training split
 train <- subset(all_df, data_split == TRUE)
 test <-subset(all_df, data_split == FALSE)

#seperating into ind and dep variables for later 
 
all_dbr <- all_df$dbr #just dependent variables
test_dbr <- test$dbr
train_dbr <- train$dbr
summ_dbr <- summ_df$dbr

all_ind <- all_df %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)
test_ind <- test %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)
train_ind <- train %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)
summ_ind <- summ_df %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)
 
 
```

## Set up OLS model

```{r OLS}

#create the model (using all data for now)
#current model doesn't include precip/temp/humid during the fire or solar radiation data
ols1 <- lm(dbr ~ slope + aspect + dem + LivingBio + DeadBio + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + month_humid + week_humid, 
          data = all_df)

#summary(ols)

#Check fit 
all_df$pred_dbr <- predict(ols1, newdata = all_df)

ggplot(all_df) +
  geom_point(aes(x = dbr, y = pred_dbr), alpha = 0.4) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

#Fit is pretty bad so far (tendancy to dramatically underestimate dbr)

#using data average across all fires
ols2 <- lm(dbr ~ slope + aspect + dem + LivingBio + DeadBio + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + month_humid + week_humid, 
          data = summ_df)

summ_df$pred_dbr <- predict(ols2, newdata = summ_df)

ggplot(summ_df) +
  geom_point(aes(x = dbr, y = pred_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

```

```{r OLS stepwise}
#trying a stepwise function to select only most relevant variables

control <- trainControl(method = "repeatedcv", number = 10, selectionFunction = "best") #this controls the settings for the model selection (10-fold cross validation currently)

all_step <- train(x = all_ind, 
                  y = all_dbr, 
                  form = ols1, 
                  data = all_df,
                  method = "leapSeq", #stepwise version of function
                  tuneGrid = data.frame(nvmax = 1:14),
                  trControl = control) #using settings from above

#summary(all_step)

#Using a stepwise model selector based on AIC 
#Input is the linear model (w/ all parameters) derived above 
#k - degrees of freedom for penalty (2 for true AIC); direction - both (try adding and substracting terms)
AIC_ols <- stepAIC(ols1, direction = "both", k = 2)

extractAIC(AIC_ols) #Stepwise dropped month_precip and fire duration based on fit; not sure if we should trust this??

summary(AIC_ols)

all_df$step_dbr <- predict(AIC_ols, newdata = all_df) #predict using pared down model

ggplot(all_df) + #doesn't seem to make much difference
  geom_point(aes(x = dbr, y = step_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

#Using averaged data for step_AIC
AIC_ols2 <- stepAIC(ols2, direction = "both", k = 2)

extractAIC(AIC_ols2) #Stepwise dropped month_precip and fire duration based on fit; not sure if we should trust this??

summary(AIC_ols2)

summ_df$step_dbr <- predict(AIC_ols2, newdata = summ_df) #predict using pared down model

ggplot(summ_df) + #doesn't seem to make much difference
  geom_point(aes(x = dbr, y = step_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()


```

```{r LASSO}
#trying LASSO

#all data points
all_x <- as.matrix(all_ind)
all_y <- as.matrix(all_dbr)

all_lasso <- cv.glmnet(x = all_x, y = all_y, 
                           family = "gaussian", standardize = TRUE, 
                           intercept = TRUE, alpha = 1)
all_df$lasso_dbr <- predict(all_lasso, newx= all_x) 

ggplot(all_df) + #even worse spread than OLS
  geom_point(aes(x = dbr, y = lasso_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

#using fire-wide averages

summ_x <- as.matrix(summ_ind)
summ_y <- as.matrix(summ_dbr)

summ_lasso <- cv.glmnet(x = summ_x, y = summ_y, 
                           family = "gaussian", standardize = TRUE, 
                           intercept = TRUE, alpha = 1)
summ_df$lasso_dbr <- predict(summ_lasso, newx= summ_x) 

ggplot(summ_df) + #this is somehow even worse???
  geom_point(aes(x = dbr, y = lasso_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

```

```{r RR}
#trying ridge regression
#note: also tried elastic net here with almost identical results

#all data points
all_rr <- cv.glmnet(x = all_x, y = all_y, 
                           family = "gaussian", standardize = TRUE, 
                           intercept = TRUE, alpha = 0) #changing alpha from 1 to 0 changes it to RR
all_df$rr_dbr <- predict(all_rr, newx= all_x) 

ggplot(all_df) + #even worse spread than OLS
  geom_point(aes(x = dbr, y = rr_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

#using fire-wide averages

summ_rr <- cv.glmnet(x = summ_x, y = summ_y, 
                           family = "gaussian", standardize = TRUE, 
                           intercept = TRUE, alpha = 0)
summ_df$rr_dbr <- predict(summ_rr, newx= summ_x) 

ggplot(summ_df) + #this is somehow even worse???
  geom_point(aes(x = dbr, y = rr_dbr), alpha = 0.4) +
  geom_abline(slope = 1) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

```


```{r RF}





```
