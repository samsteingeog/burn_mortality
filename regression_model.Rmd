---
title: "Regression"
author: "Sam Stein"
date: "4/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(lubridate)
library(caTools)
library(caret)
library(MASS)

```

## Join data sources


```{r read data}
#import Yiyi's file with data from 10k sample points
sample_pts <- read_csv("data/sample_pts")

#clean up date values
sample_pts$ALARM_DATE <- ymd_hms(sample_pts$ALARM_DATE) #change from char to date
sample_pts$CONT_DATE <- ymd_hms(sample_pts$CONT_DATE)
#sample_pts$duration <- as.numeric(sample_pts$duration) #couldn't figure out how to extract just first digits of string (maybe a regex?)
sample_pts$fireduration <- interval(sample_pts$ALARM_DATE, sample_pts$CONT_DATE) %>% #coerce duration dates into time values
  as.duration()
```

```{r make final tables}

all_data <- full_join(sample_pts, fires_weather, by = "OBJECTID") %>%
  dplyr::select(-ALARM_DATE.y, -CONT_DATE.y, -Shape_Leng.y, -YEAR_, -STATE) #drop extraneous variables

# make exportable version
 all_df <- all_data %>%
   dplyr::select(-geometry)

# write.csv(all_df, file = "all_data.csv")

#confirm that data seems correct 
summary(all_df)  

#drop missing values for DEM and derived data
#drop values without info on dbr
all_df <- all_df %>%  
  filter(!(dem == -9999)) %>%
  filter(!(dbr == 0))
 
# Test/Train split
 set.seed(1)
 
 data_split = sample.split(all_df, SplitRatio = 0.75) #setting up testing and training split
 train <- subset(all_df, data_split == TRUE)
 test <-subset(all_df, data_split == FALSE)

```

## Set up OLS model

```{r OLS}

#create the model (using all data for now)
#current model doesn't include precip/temp/humid during the fire or solar radiation data
ols1 <- lm(dbr ~ slope + aspect + dem + LivingBio + DeadBio + fireduration + GIS_ACRES + 
          month_temp + week_temp + month_precip + week_precip + wind_speed + month_humid + week_humid, 
          data = all_df)

#summary(ols)

#Check fit on train data
all_df$pred_dbr <- predict(ols1, newdata = all_df)

ggplot(all_df) +
  geom_point(aes(x = dbr, y = pred_dbr), alpha = 0.4) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()

#Fit is pretty bad so far (tendancy to dramatically underestimate dbr)

```

```{r OLS stepwise}
#trying a stepwise function to select only most relevant variables

all_dbr <- all_df$dbr #just dependent variables

all_ind <- all_df %>% #just independent variables
  dplyr::select(slope, aspect, dem, LivingBio, DeadBio, fireduration, GIS_ACRES, 
          month_temp, week_temp, month_precip, week_precip, wind_speed, month_humid, week_humid)

control <- trainControl(method = "repeatedcv", number = 10, selectionFunction = "best") #this controls the settings for the model selection (10-fold cross validation currently)

all_step <- train(x = all_ind, 
                  y = all_dbr, 
                  form = ols1, 
                  data = all_df,
                  method = "leapSeq", #stepwise version of function
                  tuneGrid = data.frame(nvmax = 1:14),
                  trControl = control) #using settings from above

#summary(all_step)

#Using a stepwise model selector based on AIC 
#Input is the linear model (w/ all parameters) derived above 
#k - degrees of freedom for penalty (2 for true AIC); direction - both (try adding and substracting terms)
AIC_ols <- stepAIC(ols1, direction = "both", k = 2)

extractAIC(AIC_ols) #Stepwise dropped month_precip and fire duration based on fit; not sure if we should trust this??

summary(AIC_ols)

all_df$step_dbr <- predict(AIC_ols, newdata = all_df) #predict using pared down model

ggplot(all_df) + #doesn't seem to make much difference
  geom_point(aes(x = dbr, y = step_dbr), alpha = 0.4) +
  xlim(0,1000) +
  ylim(0,1000) +
  theme_minimal()


```

